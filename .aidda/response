 
File: /home/stevegt/lab/grid-cli/v2/doc/01.md
```
# Design and Discussion Notes from All Files

## Overview

This document consolidates all design and discussion notes from various files to provide a comprehensive view of the architectural principles and strategic considerations guiding the development of PromiseGrid. This includes integration of the fundamental principles outlined in previous documents and merging in the contents of `141-cache.md`.

## Core Concepts

### Decentralized Architecture

PromiseGrid operates as a decentralized computing, communications, and governance system. It is designed to be owned and operated by its users rather than any single entity, ensuring distributed control and ownership.

### Capability-as-Promise Model

Capabilities are treated as promises, similar to concepts from Promise Theory. A capability token represents a promise that can either be fulfilled or revoked, establishing trust and accountability within the system.

### Content-Addressable Code

Both code and data are addressed by their content, not by location or name. This design enables the grid to store, execute code, and access data from any node in the network efficiently, leveraging the integrity ensured by content-addressable storage.

### Promises All the Way Down

Every interaction in the system is based on promises. A response to a promise is another promise, creating a network where all entities are interlinked through a chain of commitments, fostering reliability and traceability.

### Non-Sandboxed Modules

Non-sandboxed modules in PromiseGrid are comparable to device drivers in a microkernel OS. These modules handle specific external operations such as network communications and file access. The kernel delegates these operations to non-sandboxed modules while maintaining overall control.

Non-sandboxed modules SHOULD be loaded from the embedded cache to
improve local security.

## Cache and Promise Handling in the PromiseGrid Kernel

### Cache Structures

- There **MAY BE** multiple caches, including the built-in cache in the kernel and caches provided by various modules.
- The kernel **SHOULD** load the built-in cache from embedded resources using Go’s `embed` feature.
- The kernel **MAY** use the Origin Private File System (OPFS) for disk file access and **MAY** utilize the `afero` library to abstract filesystem interactions.

### Treating Modules as Caches

#### Role of Modules

- The kernel **MUST** treat modules as caches. In the event of a cache miss, the kernel **MUST** consult one or more modules to retrieve the requested value.
- Modules **MAY** contribute to the cache or provide the requested data dynamically.

#### Unified Interface

- From the caller's perspective, there **SHALL BE** no difference between a cache lookup and a function call. Both operations **SHALL BE** treated as byte sequence completion operations.  The caller sends a message consisting of a byte sequence, and receives a response message containing the remainder of the sequence.

### Acceptance and Promises

#### Acceptance Criteria

- Modules **MUST** define acceptance criteria for promises, module hashes, and arguments. This can be implemented as an interface for modules, simplifying acceptance to a single `Accept()` function.

#### Promises as Acceptance

- By returning a promise message from `Accept` instead of a boolean, modules provide additional guarantees and meta-information. The acceptance is treated as a commitment to handle the message correctly. If `HandleMessage` fails, it is considered a broken promise.

#### Ant Routing Mechanism

- The syscall tree acts as an "ant routing" mechanism, caching successful paths to optimize future routing. In future similar calls, the same path will be followed to the same module.
- The syscall tree **MUST** use hierarchical keys and **SHOULD** filter based on whether any module accepts the leading parameters, matches the module hash, and accepts the arguments.

## Integration with Church, Turing, and Chomsky's Concept of "Accept"

1. **Computational Theory**:
    - The term "accept" aligns with Church, Turing, and Chomsky's use in computing theory and languages, where an automaton or machine accepts an input if it reaches an accepting state.
    - In PromiseGrid, modules act as recognizers for specific tasks based on the promise hash, module hash, and arguments.

2. **Promises All the Way Down**:
    - The concept of "promises all the way down" integrates acceptance as a promise message, enhancing robustness and trustworthiness.
    - Each layer (modules, syscall tree, kernel) makes and fulfills promises based on the promises made by the layers below it.

## Kernel's Dynamic Syscall Tree

### Syscall Table and Acceptance History

- The acceptanceHist and syscallTable **SHOULD BE** the same. This dynamic syscall tree **SHOULD** store acceptance history for all modules.
- The kernel **SHOULD** store positive and negative acceptance history for all modules to look up which modules accept the leading bytes, skip modules that reject those bytes, and call accepting modules with the full sequence of bytes.
- This table **SHOULD** start empty and be populated during operation as the kernel consults built-in and other modules to handle messages.
- The kernel **MUST** route messages to the module whose syscall tree key matches the most leading parameter components, optimizing routing and reducing redundant checks.

## Flexible Design for Module Registration

### Explicit Module Registration

**Pros**
1. **Clarity and Explicitness**: Modules explicitly report their capabilities, making it easier to understand the system's configuration and functionality.
2. **Fine-Grained Control**: The kernel can enforce specific rules and constraints on modules based on their declared capabilities.
3. **Dynamic Adaptation**: Modules can dynamically update their capabilities, allowing for on-the-fly changes and adaptation.

**Cons**
1. **Complexity**: The registration process adds complexity to the module initialization and management process.
2. **Performance Overhead**: The kernel must maintain and query a registry of module capabilities, which can introduce performance overhead.
3. **Dependency Management**: Changes in module capabilities may require updates to the kernel or other modules, increasing the risk of dependencies and compatibility issues.

### Hash-Based Module Routing

**Pros**
1. **Simplicity**: The kernel routes messages based on cryptographic hashes, reducing the need for an explicit registration step.
2. **Efficiency**: Hash-based routing can be highly efficient, leveraging cryptographic properties to ensure unique and consistent module addressing.
3. **Decentralized Management**: Modules are self-contained and can be managed independently without requiring kernel updates or reconfiguration.

**Cons**
1. **Opaque Mapping**: It may be less clear which module handles a specific message, as the mapping relies on hashes rather than explicit declarations.
2. **Limited Flexibility**: Modules cannot dynamically update their capabilities without changing their hash, reducing adaptability.
3. **Security Risks**: The kernel must ensure that the hash-based routing mechanism is secure against hash collisions and attacks.

## Modular Interaction and Delegation

Modules can unwrap nested messages and forward them to other modules, allowing for complex interactions and message flows. The kernel is not necessarily the final arbiter of which module handles a message.

**Implications**
1. **Delegated Control**: Modules can delegate tasks to other modules, enabling a modular and extensible system design.
2. **Dynamic Message Flows**: Nested messages allow for dynamic and context-specific message handling, improving flexibility.

### Acceptance and Handling Functions

#### Combined Function Approach

**Pros**:
1. **Simplicity**: Combines decision-making and handling into a single function.
2. **Consistency**: Ensures the decision to handle and the actual handling are tightly coupled, increasing consistency and reducing logic duplication.
3. **Efficiency**: Eliminates redundant checks by combining acceptance and handling.

#### Separate Function Approach

**Pros**:
1. **Clarity**: Maintains a clear separation between decision-making and handling logic.
2. **Early Rejection**: Allows for quick rejection of messages based on promise, module hash, or arguments without performing any handling.
3. **Modular Logic**: Facilitates modular and specialized acceptance and handling logic.

### Conclusion

Combining promises at every level and implementing a hierarchical syscall tree with caching and acceptance history ensures trust, accountability, and efficient message handling in a decentralized governance framework. The consistent handling of cache and modules contributes to a robust and flexible system, aligning with computational theory and modular architecture principles.

## Cache and Promise Handling in the PromiseGrid Kernel

### Kernel Services

- The kernel **MUST** provide a built-in cache for efficient data retrieval and storage.
- The built-in cache **SHOULD** be loaded from embedded resources using Go's `embed` feature.
- The built-in cache **MUST** include one or more modules (microkernel services) for handling filesystem and network access, dependent on which platform the kernel is running on (WASM, Linux, Windows, etc.)
- The filesystem module(s) **MAY** use the Origin Private File System (OPFS) for disk file access when running in WASM, and **MAY** use the `afero` library to abstract filesystem interactions.
- The network module(s) **MAY** use XXX for network access when running in WASM, and **MAY** use the `net` package for network interactions when native.

### Cache Structures

#### Built-In and Modular Cache

1. **Multiple Caches**:
   - There **MAY BE** multiple caches, including the built-in cache in the kernel and caches provided by various modules.
   - The kernel **SHOULD** load the built-in cache from embedded resources using Go’s `embed` feature.

2. **Filesystem Integration**:
   - Non-sandboxed modules **MAY** use the Origin Private File System (OPFS) for disk file access.
   - Non-sandboxed modules **MAY** utilize the `afero` library to abstract filesystem interactions, ensuring compatibility across different platforms.

## Treating Modules as Caches

### Unified Interface for Cache and Function Calls

1. **Role of Modules**:
   - The kernel **MUST** treat modules as caches. In the event of a cache miss, the kernel **MUST** consult one or more modules to retrieve the requested value.
   - Modules **MAY** contribute to the cache or provide the requested data dynamically.

2. **Unified Interface**:
   - From the caller's perspective, there **SHALL BE** no difference between a cache lookup and a function call. Both operations **SHALL BE** treated as byte sequence completions. The caller sends a message consisting of a byte sequence and receives a message containing the remainder of the sequence.

## internal channels, external function calls

- internally, the kernel uses Go channels 
- all modules communicate with the kernel using functions calls and
  callbacks


## Acceptance and Promises

### Acceptance as Promise

1. **Acceptance Criteria**:
   - Modules **MUST** define acceptance criteria for promises, module hashes, and arguments into a single function, `Accept()`.
   - By returning a promise message from `Accept` instead of a boolean, modules provide additional guarantees and meta-information.

2. **Promise-Based Acceptance**:
   - The `Accept` function returns a promise message including details on whether the module accepts the request and any relevant metadata. If `HandleMessage` fails, it is considered a broken promise.

### Ant Routing Mechanism

3. **Dynamic Routing and Optimization**:
   - The syscall tree acts as an "ant routing" mechanism, caching successful paths to optimize future routing. Similar future calls follow the same paths to the same module.
   - The syscall tree **MUST** use hierarchical keys and **SHOULD** filter based on whether any module accepts the leading parameters, matches the module hash, and accepts the arguments.

## Integration with Computational Theory

### Alignment with Church, Turing, and Chomsky's "Accept" Concept

1. **Computational Theory**:
   - The term "accept" aligns with the computational theory usage (Church, Turing, Chomsky), where an automaton or machine accepts an input if it reaches an accepting state.
   - In PromiseGrid, modules act as recognizers for specific tasks based on the promise hash, module hash, and arguments.

2. **Promises All the Way Down**:
   - The "promises all the way down" concept integrates acceptance as a promise message, enhancing robustness and trustworthiness.
   - Each layer (modules, syscall tree, kernel) makes and fulfills promises based on the promises made by the layers below it.

## Kernel's Dynamic Syscall Tree

### Dynamic and Optimized Message Routing

1. **Syscall Tree and Acceptance History**:
   - The kernel **SHOULD** use a dynamic syscall table to store both positive and negative acceptance histories for all modules.
   - This table **SHOULD** start empty and be populated as the kernel handles messages, consulting built-in and other modules.
   - Messages **MUST** be routed to the module whose syscall tree key matches the most leading parameters, optimizing routing efficiency and reducing redundant checks.

## Conclusion

The PromiseGrid Kernel's design for caching, module handling, and promise-based acceptance ensures a robust, flexible, and efficient system for decentralized governance and cooperation. By treating acceptance as a promise and integrating a hierarchical syscall tree with ant routing mechanisms, the kernel maintains trust, accountability, and optimized performance, consistent with principles of computational theory and modular architecture.

## Q&A

### Known Microkernel Architectures Using Capability-Based Security

- Are there any known microkernel architectures that use a capability-based security model? If so, how do they handle permissions and access control?

Yes, there are known microkernel architectures that use a capability-based security model. One notable example is the **seL4** microkernel.
- **seL4**: It's a high-assurance, high-performance microkernel developed with a strong focus on security and formal verification. In seL4, capabilities are used to control access to kernel objects, providing fine-grained access control. These capabilities are unforgeable tokens that describe what operations can be performed on objects (such as memory segments, threads, and IPC channels). The kernel maintains the mapping and distribution of these capabilities, ensuring that only authorized entities can access and manipulate kernel resources.

Handling Permissions and Access Control in **seL4**:
1. **Capabilities**: In seL4, capabilities are fundamental to its security model. Each capability specifies a set of rights to a particular object, and these rights determine what actions the holder can perform on the object.
2. **Capability Space**: Each thread/task in seL4 has a capability space, which is a structure that holds all the capabilities that the thread possesses. This ensures that threads can only operate on objects for which they have the necessary capabilities.
3. **Capability Invocation**: To perform an operation on an object, a thread must invoke the corresponding capability. The kernel then checks the rights encoded in the capability to determine whether the operation is permitted.
4. **Controlled Delegation**: Capabilities can be delegated (or propagated) to other threads, but the delegation is controlled by the kernel to prevent unauthorized access. This allows for flexible and secure sharing of resources within a system.

By leveraging a capability-based security model, microkernels like seL4 ensure that access control is both fine-grained and secure, providing a robust foundation for building secure systems.

#### Examples of Existing Microkernels

In a typical microkernel architecture, the kernel has minimal knowledge of permissions, and the responsibility for handling permissions is generally left to microservers (drivers). The kernel focuses on providing essential services such as communication and resource management, while higher-level functions, including access control and permissions, are managed by user-level services.

1. **seL4**: As previously mentioned, seL4 uses a capability-based security model where the kernel maintains capability mappings but does not deeply involve itself in access control logic. Instead, it relies on the capabilities held by the user-level services to determine access rights.

2. **Mach**: The Mach microkernel provides basic Inter-Process Communication (IPC) mechanisms and leaves most of the higher-level functionality, including access control, to user-space programs. The kernel does not have intrinsic knowledge of the permissions but enforces access controls passed to it via messages.

3. **L4**: The L4 microkernel architecture also uses a minimalistic design philosophy, where the kernel provides basic mechanisms, and policy, including permissions, is implemented in user space. Access control is managed through capabilities issued and checked by user-space services.

By delegating permission and access control management to microservers or user-level services, microkernel architectures can maintain a small and efficient core, allowing for easier verification and higher reliability.

### Microkernel interaction with userland drivers

- How do microkernels interact with userland drivers?  Does the driver register with the kernel, or does the kernel load the driver as a part of the boot process, already knowing about the driver's address space and abilities?

Microkernels interact with userland drivers through a well-defined communication interface, usually using Inter-Process Communication (IPC) mechanisms. The typical process is as follows:

1. **Registration**: Userland drivers register with the microkernel during the system's initialization phase. The registration involves specifying the driver's capabilities and the resources it will manage. During this process, the kernel may allocate specific address spaces and IPC channels for communication with the driver.

2. **Dynamic Loading**: The kernel does not necessarily need to know about the driver's address space and abilities beforehand. Drivers can be dynamically loaded as required, allowing for a more modular and flexible system. The microkernel will map the driver's address space as part of the registration or loading process.

3. **Message Passing**: Once loaded and initialized, userland drivers interact with the kernel and other system components via message passing. This interaction can include handling hardware interrupts, servicing IO requests, or managing other resources. The microkernel facilitates this communication through its IPC mechanism, ensuring that messages are delivered to the appropriate recipient.

In summary, userland drivers typically register with the kernel, which then maps their address spaces and sets up communication channels. These drivers can be dynamically loaded, allowing the kernel to extend its capabilities without needing to know about the driver specifics in advance.

### Caches, Invocation, and Logging

### How do we know when we need to load a module from the cache, execute it, and store the result back in the cache?

In the PromiseGrid Kernel, the determination of when to load a module from the cache, execute it, and store the result back in the cache follows a systematic approach:

1. **Cache Lookup**: When a message arrives, the kernel first performs a cache lookup using the leading hash (capability token, function address) and the provided arguments. If the requested function call and its arguments are already in the cache, the kernel retrieves and returns the cached result.

2. **Cache Miss**: If the cache lookup fails (cache miss), the kernel proceeds to consult the appropriate module(s) to handle the request. This involves invoking the module's function corresponding to the capability token and passing the arguments from the message.

3. **Module Execution**: The module executes the function with the given arguments. During this execution, the module can dynamically generate the response based on the input or retrieve the necessary data from other sources.

4. **Store Result in Cache**: Once the module generates the response, the kernel stores this result back in the cache. This ensures that subsequent requests with the same capability token and arguments can be served directly from the cache, optimizing future retrievals and reducing redundant computations.

By following this procedure, the PromiseGrid Kernel ensures efficient use of the cache while leveraging modular execution to handle cache misses. This approach harmonizes decentralized cache handling with the overall system's modular and promise-based architecture.

## Open Questions About Caching Mechanisms