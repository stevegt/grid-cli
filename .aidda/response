   
File: /home/stevegt/lab/grid-cli/v2/doc/141-cache.md
```
# Cache and Promise Handling in the PromiseGrid Kernel

## Introduction

In the PromiseGrid Kernel, caching and module handling are crucial for optimizing the retrieval and execution of data. This document outlines the strategies and implementation details for these systems, emphasizing their alignment with decentralized governance and microkernel architectural principles.

## Kernel Services

- The kernel **MUST** provide a built-in cache for efficient data retrieval and storage.
- The built-in cache **SHOULD** be loaded from embedded resources using Go's `embed` feature.
- The built-in cache **MUST** include one or more modules (microkernel services) for handling filesystem and network access, dependent on which platform the kernel is running on (WASM, Linux, Windows, etc.)
- The filesystem module(s) **MAY** use the Origin Private File System (OPFS) for disk file access when running in WASM, and **MAY** use the `afero` library to abstract filesystem interactions.
- The network module(s) **MAY** use XXX for network access when running in WASM, and **MAY** use the `net` package for network interactions when native.

## Cache Structures

### Built-In and Modular Cache

1. **Multiple Caches**:
   - There **MAY BE** multiple caches, including the built-in cache in the kernel and caches provided by various modules.
   - The kernel **SHOULD** load the built-in cache from embedded resources using Goâ€™s `embed` feature.

2. **Filesystem Integration**:
   - The kernel **MAY** use the Origin Private File System (OPFS) for disk file access.
   - The kernel **MAY** utilize the `afero` library to abstract filesystem interactions, ensuring compatibility across different platforms.

## Treating Modules as Caches

### Unified Interface for Cache and Function Calls

1. **Role of Modules**:
   - The kernel **MUST** treat modules as caches. In the event of a cache miss, the kernel **MUST** consult one or more modules to retrieve the requested value.
   - Modules **MAY** contribute to the cache or provide the requested data dynamically.

2. **Unified Interface**:
   - From the caller's perspective, there **SHALL BE** no difference between a cache lookup and a function call. Both operations **SHALL BE** treated as hashed function calls. The caller sends a message with a leading hash and any arguments and receives a message containing the requested content.

## Acceptance and Promises

### Acceptance as Promise

1. **Acceptance Criteria**:
   - Modules **MUST** define acceptance criteria for promises, module hashes, and arguments into a single function, `Accept()`.
   - By returning a promise message from `Accept` instead of a boolean, modules provide additional guarantees and meta-information.

2. **Promise-Based Acceptance**:
   - The `Accept` function returns a promise message including details on whether the module accepts the request and any relevant metadata. If `HandleMessage` fails, it is considered a broken promise.

### Ant Routing Mechanism

3. **Dynamic Routing and Optimization**:
   - The syscall tree acts as an "ant routing" mechanism, caching successful paths to optimize future routing. Similar future calls follow the same paths to the same module.
   - The syscall tree **MUST** use hierarchical keys and **SHOULD** filter based on whether any module accepts the leading parameters, matches the module hash, and accepts the arguments.

## Integration with Computational Theory

### Alignment with Church, Turing, and Chomsky's "Accept" Concept

1. **Computational Theory**:
   - The term "accept" aligns with the computational theory usage (Church, Turing, Chomsky), where an automaton or machine accepts an input if it reaches an accepting state.
   - In PromiseGrid, modules act as recognizers for specific tasks based on the promise hash, module hash, and arguments.

2. **Promises All the Way Down**:
   - The "promises all the way down" concept integrates acceptance as a promise message, enhancing robustness and trustworthiness.
   - Each layer (modules, syscall tree, kernel) makes and fulfills promises based on the promises made by the layers below it.

## Kernel's Dynamic Syscall Tree

### Dynamic and Optimized Message Routing

1. **Syscall Tree and Acceptance History**:
   - The kernel **SHOULD** use a dynamic syscall table to store both positive and negative acceptance histories for all modules.
   - This table **SHOULD** start empty and be populated as the kernel handles messages, consulting built-in and other modules.
   - Messages **MUST** be routed to the module whose syscall tree key matches the most leading parameters, optimizing routing efficiency and reducing redundant checks.

## Conclusion

The PromiseGrid Kernel's design for caching, module handling, and promise-based acceptance ensures a robust, flexible, and efficient system for decentralized governance and cooperation. By treating acceptance as a promise and integrating a hierarchical syscall tree with ant routing mechanisms, the kernel maintains trust, accountability, and optimized performance, consistent with principles of computational theory and modular architecture.

## Q&A

### Known Microkernel Architectures Using Capability-Based Security

- Are there any known microkernel architectures that use a capability-based security model? If so, how do they handle permissions and access control?

Yes, there are known microkernel architectures that use a capability-based security model. One notable example is the **seL4** microkernel.
- **seL4**: It's a high-assurance, high-performance microkernel developed with a strong focus on security and formal verification. In seL4, capabilities are used to control access to kernel objects, providing fine-grained access control. These capabilities are unforgeable tokens that describe what operations can be performed on objects (such as memory segments, threads, and IPC channels). The kernel maintains the mapping and distribution of these capabilities, ensuring that only authorized entities can access and manipulate kernel resources.

Handling Permissions and Access Control in **seL4**:
1. **Capabilities**: In seL4, capabilities are fundamental to its security model. Each capability specifies a set of rights to a particular object, and these rights determine what actions the holder can perform on the object.
2. **Capability Space**: Each thread/task in seL4 has a capability space, which is a structure that holds all the capabilities that the thread possesses. This ensures that threads can only operate on objects for which they have the necessary capabilities.
3. **Capability Invocation**: To perform an operation on an object, a thread must invoke the corresponding capability. The kernel then checks the rights encoded in the capability to determine whether the operation is permitted.
4. **Controlled Delegation**: Capabilities can be delegated (or propagated) to other threads, but the delegation is controlled by the kernel to prevent unauthorized access. This allows for flexible and secure sharing of resources within a system.

By leveraging a capability-based security model, microkernels like seL4 ensure that access control is both fine-grained and secure, providing a robust foundation for building secure systems.

### Integration with Userland Drivers in Microkernels

- How do microkernels interact with userland drivers? Does the driver register with the kernel, or does the kernel load the driver as a part of the boot process, already knowing about the driver's address space and abilities?

Microkernels interact with userland drivers through Inter-Process Communication (IPC), and the typical process can include both registration and dynamic loading:

1. **Registration**: Userland drivers register with the microkernel during system initialization. During this process, the kernel allocates specific address spaces and IPC channels for communication with the driver.
2. **Dynamic Loading**: Drivers can be dynamically loaded as required, without the kernel necessarily knowing about them beforehand. During loading, the driver's address space is mapped, and the necessary resources are allocated.
3. **Message Passing**: Drivers communicate with the kernel and other system components via message passing, handling tasks like hardware interrupts, I/O requests, or resource management through IPC mechanisms.

### Caches, Invocation, and Logging

- How do we know when we need to load a module from the cache, execute it, and store the result back in the cache?

In the PromiseGrid Kernel, the determination of when to load a module from the cache, execute it, and store the result back in the cache follows this systematic approach:

1. **Cache Lookup**: On receiving a message, the kernel first performs a cache lookup using the leading hash (capability token, function address) and the provided arguments. If a match is found, the cached result is returned.
2. **Cache Miss Handling**: If the lookup fails (cache miss), the kernel consults the appropriate module(s) to handle the request. The module generates the response dynamically.
3. **Caching Result**: The result is stored back in the cache using the same keys (hash and arguments) to ensure future efficiency. The result includes a signature from the handler certifying its accuracy, ensuring integrity and trustworthiness.

By following this procedure, the PromiseGrid Kernel ensures efficient processing of requests while dynamically managing cache content.

## Open Questions About Caching Mechanisms

- Does the cache even need to know anything about modules, or is it just a simple nested key-value store?

The cache in the PromiseGrid kernel is designed to be a simple nested key-value store, facilitating the efficient retrieval of messages based on their positional parameters. It is not necessary for the cache to know about the specifics of modules, promises, or protocols; it primarily manages the storage and retrieval of messages.

- Should cache nodes include a field that flags them as being an executable, an argument, or a result message? Or should it be implied that the first key field is always an executable and the remaining fields are positional arguments?

The cache nodes and their contents must align with the system's ability to manage promises efficiently:

1. **Cache Nodes with Flags**: Including a field in the cache node that marks or flags it as being an executable, an argument, or a result message may add clarity when managing diverse cache entries.
2. **Implied Execution**: Alternatively, assuming that the first key field is always an executable, and the remaining fields are positional arguments provides a streamlined approach. This is simpler for consistent handling across the cache tree.

### Example of How the System Can Handle Cache and Module Execution:

- **Message Processing Flow**:
  - The system receives a message with a byte sequence.
  - The leading bytes are used for cache lookup.
  - On a cache miss, the kernel invokes the appropriate module to handle or complete the message.
  - The result is stored back in the cache for future lookups.

- **Cache Management**:
  - Cache stores messages based on positional parameters, with leading bytes indicating executables.
  - Modules and handlers validate, process, and generate results stored back into the cache.
  - Cache nodes may include metadata or flags as necessary, facilitating efficient and reliable cache management and message processing.

This comprehensive approach ensures that PromiseGrid's cache and module operations remain efficient, predictable, and aligned with the system's architectural principles.
```
EOF_/home/stevegt/lab/grid-cli/v2/doc/141-cache.md
```
EOF_/home/stevegt/lab/grid-cli/v2/doc/141-cache.md